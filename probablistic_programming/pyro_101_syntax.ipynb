{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import AbstractContextManager\n",
    "import rich\n",
    "import torch\n",
    "import numpy as np\n",
    "import pyro\n",
    "from pyro import distributions as dist\n",
    "from pyro import poutine\n",
    "from pyro.infer import Trace_ELBO, TraceEnum_ELBO, SVI\n",
    "from pyro.infer import config_enumerate, infer_discrete\n",
    "from pyro.distributions import constraints\n",
    "from pyro.ops.indexing import Vindex\n",
    "from pyro.infer.autoguide import AutoNormal, AutoDelta, AutoGuide\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "class catch(AbstractContextManager):\n",
    "    def __init__(self, info = None):\n",
    "        self.info = info\n",
    "\n",
    "    def __enter__(self):\n",
    "        if self.info is not None:\n",
    "            print(f\"=== {self.info} ===\")\n",
    "\n",
    "    def __exit__(self, exctype, excinst, exctb):\n",
    "        if exctype is not None:\n",
    "            print(f\"Error: {exctype}\")\n",
    "        return True\n",
    "\n",
    "\n",
    "def render_model_plus(model, model_args=None):\n",
    "    display.display(\n",
    "        pyro.render_model(model, model_args, render_params=True, render_distributions=True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some differences between `param` and `sample`:\n",
    "- different shapes:\n",
    "    - for Normal, sample(param(shape=[5, 2]))=[5, 2]\n",
    "    - for Categorical, sample(param(shape=[5, 2]))=[5]\n",
    "- static vs dynamic: \n",
    "    - `param` will be reused if not `clear_param_store`\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== param ===\")\n",
    "pyro.clear_param_store()\n",
    "print(pyro.param(\"p\", torch.randn(3, 3).exp(), constraint=constraints.simplex).shape)\n",
    "print(pyro.param(\"p\", torch.randn(5, 4, 3, 2).exp(), constraint=constraints.simplex).shape)\n",
    "pyro.clear_param_store()\n",
    "print(pyro.param(\"p\", torch.randn(5, 4, 3, 2).exp(), constraint=constraints.simplex).shape)\n",
    "\n",
    "print(\"=== sample ===\")\n",
    "print(pyro.sample(\"p\", dist.Normal(0., 1.).expand([5, 2])).shape)\n",
    "print(pyro.sample(\"p\", dist.Normal(0., 1.).expand([3, 2])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    AutoNormal creates a Normal(loc, scale) for each param\n",
    "\"\"\"\n",
    "pyro.clear_param_store()\n",
    "\n",
    "def model():\n",
    "    p = pyro.param(\"loc\", torch.tensor(0.0))\n",
    "    x = pyro.sample(\"x\", dist.Normal(p, 1))\n",
    "    y = pyro.sample(\"y\", dist.Normal(x, 1))\n",
    "\n",
    "render_model_plus(model)\n",
    "render_model_plus(AutoNormal(model))\n",
    "render_model_plus(AutoDelta(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Be careful about the shape of a distribution!\n",
    "\n",
    "    Categorical(shape=[5, 2])'s batch_shape is [5]\n",
    "    Normal(shape=[5, 2])'s batch_shape is [5, 2]\n",
    "\"\"\"\n",
    "\n",
    "def print_shape(some_dist: dist.Distribution):\n",
    "    print(\"Shape: \", some_dist.batch_shape, some_dist.event_shape)\n",
    "\n",
    "print(\"=== Normal ===\")\n",
    "print_shape(dist.Normal(0., 10.))\n",
    "print_shape(dist.Normal(0., 10.).expand([5, 2]))\n",
    "print_shape(dist.Normal(0., 10.).expand([5, 2]).to_event(1))\n",
    "\n",
    "def cat(*shape):\n",
    "    return dist.Categorical(torch.randn(*shape).exp())\n",
    "\n",
    "print(\"=== Categorical ===\")\n",
    "print_shape(cat(5))\n",
    "print_shape(cat(2).expand([5]))\n",
    "print_shape(cat(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Distribution contains `batch_shape` and `event_shape`, represented by [batch_shape | event_shape]\n",
    "    \n",
    "    The constraint must be satisfied:\n",
    "        plate's size = Distribution's batch_shape[dim]\n",
    "\"\"\"\n",
    "with pyro.plate('k', size=2, dim=None): \n",
    "    normal = dist.Normal(0., 10.)\n",
    "    with catch(\"无法给 [3, 4 | ] 设置 size=2 的维度\"):\n",
    "        x = pyro.sample('x', normal.expand([3, 4]))\n",
    "        print(x.shape) \n",
    "    with catch(\"可以给 [ | 3, 4] 设置 size=2 的维度，偷偷做了 broadcast\"):\n",
    "        x = pyro.sample('x', normal.expand([3, 4]).to_event(2))\n",
    "        print(x.shape)\n",
    "    with catch(\"无法给 [2, 4 | ] 设置 size=2 的维度\"):\n",
    "        x = pyro.sample('x', normal.expand([2, 4]))\n",
    "        print(x.shape)\n",
    "    with catch(\"可以给 [2 | 4] 设置 size=2 的维度\"):\n",
    "        x = pyro.sample('x', normal.expand([2, 4]).to_event(1))\n",
    "        print(x.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## poutines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    trace & replay\n",
    "\"\"\"\n",
    "def model_1(x):\n",
    "    s = pyro.param(\"s\", torch.tensor(0.5))\n",
    "    z = pyro.sample(\"z\", dist.Normal(x, s))\n",
    "    print(f\"[model_1] draw z = {z}\")\n",
    "\n",
    "def model_2(x):\n",
    "    z = pyro.sample(\"z\", dist.Normal(x, 4))\n",
    "    print(f\"[model_2] draw z = {z}\")\n",
    "    z2 = pyro.sample(\"z2\", dist.Normal(x, 4))\n",
    "    print(f\"[model_2] draw z2 = {z2}\")\n",
    "\n",
    "print(\"=== Vanilla behaviour ===\")\n",
    "print(\"model_1 and model_2 should sample very different z:\")\n",
    "model_1(1.0)\n",
    "model_2(1000.0)\n",
    "\n",
    "print(\"=== Traced behaviour ===\")\n",
    "print(\"If we replay model_1's trace in model_2, `sample` will be deterministic:\")\n",
    "trace_model_1 = pyro.poutine.trace(model_1)\n",
    "model_1_trace = trace_model_1.get_trace(1.0)\n",
    "replayed_model_2 = pyro.poutine.replay(model_2, trace=model_1_trace)\n",
    "replayed_model_2(1000.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    block makes some site invisible\n",
    "    condition = sample(obs=~)\n",
    "\"\"\"\n",
    "def model():\n",
    "    a = pyro.sample(\"a\", dist.Normal(0., 1.))\n",
    "    b = pyro.sample(\"b\", dist.Normal(a, 1.))\n",
    "\n",
    "pyro.render_model(poutine.block(model, expose=['b']))\n",
    "pyro.render_model(poutine.condition(model, data={\"b\": torch.tensor(1.0)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    We construct the graph in model(),\n",
    "        but we can modify it with `poutine.condition` to make some variables visible\n",
    "        concretely, the process is:\n",
    "            - sample x from N(0, 1)\n",
    "            - set y to be 1 (but we view it as a sample from N(x, 1))\n",
    "            - sample z from N(x, y)\n",
    "        we can compute all log-probs (by a sampling path, not marginalized)!\n",
    "\"\"\"\n",
    "def model():\n",
    "    x = pyro.sample(\"x\", dist.Normal(0, 1))\n",
    "    y = pyro.sample(\"y\", dist.Normal(x, 1))\n",
    "    z = pyro.sample(\"z\", dist.Normal(x, y))\n",
    "    print(\"log-prob-sum should be:\",\n",
    "          dist.Normal(0, 1).log_prob(x) +  #\n",
    "          dist.Normal(x, 1).log_prob(y) +  #\n",
    "          dist.Normal(x, y).log_prob(z))\n",
    "\n",
    "\n",
    "obs_y_model = poutine.condition(model, data={\"y\": torch.tensor(1.0)})\n",
    "trace = poutine.trace(obs_y_model).get_trace()\n",
    "print(\"traced log-prob-sum:\", trace.log_prob_sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom_guide\n",
      "Step 0\n",
      "tensor([ 0,  1,  2, 11, 12, 13, 14, 15])\n",
      "Step 1\n",
      "tensor([ 0,  1,  2, 11, 12, 13, 14, 15])\n",
      "Step 2\n",
      "tensor([ 0,  1,  2, 11, 12, 13, 14, 15])\n",
      "Using auto_guide\n",
      "Step 0\n",
      "tensor([ 0,  1,  2, 11, 12, 13, 14, 15])\n",
      "tensor([ 0,  1,  2, 11, 12, 13, 14, 15])\n",
      "Step 1\n",
      "tensor([ 0,  1,  2, 11, 12, 13, 14, 15])\n",
      "Step 2\n",
      "tensor([ 0,  1,  2, 11, 12, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    If we use AutoGuide, pyro will forward the model to know what the graph looks like,\n",
    "    such that it can build a guide graph.\n",
    "\n",
    "    So the model run TWICE in the first call to `svi.step()`\n",
    "\"\"\"\n",
    "def model(data):\n",
    "    print(data)\n",
    "    loc = pyro.sample(\"weights\", dist.Normal(0.0, 1.0))\n",
    "    scale = pyro.sample(\"scale\", dist.LogNormal(0.0, 10.0))\n",
    "    with pyro.plate(\"data\", len(data)):\n",
    "        obs_dist = dist.Normal(loc, scale)\n",
    "        obs = pyro.sample(\"obs\", obs_dist, obs=data)\n",
    "\n",
    "def custom_guide(data):\n",
    "    loc = pyro.sample(\"weights\", dist.Normal(0.0, 1.0))\n",
    "    scale = pyro.sample(\"scale\", dist.LogNormal(0.0, 10.0))\n",
    "\n",
    "data = torch.tensor([0, 1, 2, 11, 12, 13, 14, 15])\n",
    "pyro.clear_param_store()\n",
    "\n",
    "auto_guide = AutoDelta(model)\n",
    "elbo = Trace_ELBO()\n",
    "opt = pyro.optim.AdamW({\"lr\": 0.1})\n",
    "\n",
    "\n",
    "for name, guide in {\"custom_guide\": custom_guide, \"auto_guide\": auto_guide}.items():\n",
    "    print(f\"Using {name}\")\n",
    "    svi = SVI(model, guide, opt, elbo)\n",
    "\n",
    "    for i in range(3):\n",
    "        print(f\"Step {i}\")\n",
    "        svi.step(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "torch.Size([8]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([8]) torch.Size([8]) torch.Size([8])\n",
      "torch.Size([2, 1]) torch.Size([2, 1]) torch.Size([8])\n",
      "Step 1\n",
      "torch.Size([2, 1]) torch.Size([2, 1]) torch.Size([8])\n",
      "Step 2\n",
      "torch.Size([2, 1]) torch.Size([2, 1]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    enumerate only works for distributions, which are:\n",
    "        - NOT observed\n",
    "        - discrete\n",
    "    \n",
    "    enumerate's effect:\n",
    "        sample: [num_data] -> enumerate: [num_categories, 1] (the last is left for batch)\n",
    "\n",
    "\"\"\"\n",
    "@config_enumerate\n",
    "def model(data):\n",
    "    weights = pyro.sample(\"weights\", dist.Dirichlet(0.5 * torch.ones(2)))\n",
    "    with pyro.plate(\"components\", 2):\n",
    "        loc = pyro.sample(\"loc\", dist.Normal(5, 3))\n",
    "        scale = pyro.sample(\"scale\", dist.LogNormal(0, 3))\n",
    "    # ↑ For continious distribution, the shape is same before/after enumerate.\n",
    "    # print(weights.shape, loc.shape, scale.shape)\n",
    "    with pyro.plate(\"data\", len(data)):\n",
    "        # ↓ For discrete distribution (Categorical), [8] (w/o enumerate) -> [2, 1] (w/ enumerate)\n",
    "        # The key here is: for each data point, if we sample a component individually\n",
    "        # for each data, we have to sample |data| times. However:\n",
    "        #   - sampling too early prevents us from marginalization\n",
    "        #   - most of the sampling cause redundant computation (|components| << |data|)\n",
    "        assignment = pyro.sample(\"assignment\", dist.Categorical(weights))\n",
    "        obs_dist = dist.Normal(loc[assignment], scale[assignment])\n",
    "        obs = pyro.sample(\"obs\", obs_dist, obs=data)\n",
    "        print(assignment.shape, obs_dist.batch_shape, obs.shape)\n",
    "\n",
    "data = torch.tensor([0, 1, 2, 11, 12, 13, 14, 15])\n",
    "pyro.clear_param_store()\n",
    "\n",
    "guide = AutoDelta(poutine.block(model, hide=['assignment']))\n",
    "elbo = TraceEnum_ELBO(num_particles=1)\n",
    "opt = pyro.optim.AdamW({\"lr\": 0.1})\n",
    "svi = SVI(model, guide, opt, elbo)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Step {i}\")\n",
    "    svi.step(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sampling ===\n",
      "     p.shape = torch.Size([5, 4, 3, 2])\n",
      "     x.shape = torch.Size([])\n",
      "     y.shape = torch.Size([])\n",
      "  p_xy.shape = torch.Size([5, 2])\n",
      "     z.shape = torch.Size([5])\n",
      "=== Enumerated Inference ===\n",
      "     p.shape = torch.Size([5, 4, 3, 2])\n",
      "     x.shape = torch.Size([])\n",
      "     y.shape = torch.Size([])\n",
      "  p_xy.shape = torch.Size([5, 2])\n",
      "     z.shape = torch.Size([5])\n",
      "     p.shape = torch.Size([5, 4, 3, 2])\n",
      "     x.shape = torch.Size([4, 1])\n",
      "     y.shape = torch.Size([3, 1, 1])\n",
      "  p_xy.shape = torch.Size([3, 4, 5, 2])\n",
      "     z.shape = torch.Size([2, 1, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    What should I comment here?\n",
    "\"\"\"\n",
    "@config_enumerate\n",
    "def model():\n",
    "    p = pyro.param(\"p\", torch.randn(5, 4, 3, 2).exp(), constraint=constraints.simplex)\n",
    "    x = pyro.sample(\"x\", dist.Categorical(torch.ones(4)))\n",
    "    y = pyro.sample(\"y\", dist.Categorical(torch.ones(3)))\n",
    "    with pyro.plate(\"z_plate\", 5):\n",
    "        p_xy = Vindex(p)[..., x, y, :]\n",
    "        z = pyro.sample(\"z\", dist.Categorical(p_xy))\n",
    "    print(f\"     p.shape = {p.shape}\")\n",
    "    print(f\"     x.shape = {x.shape}\")\n",
    "    print(f\"     y.shape = {y.shape}\")\n",
    "    print(f\"  p_xy.shape = {p_xy.shape}\")\n",
    "    print(f\"     z.shape = {z.shape}\")\n",
    "    return x, y, z\n",
    "\n",
    "def guide():\n",
    "    pass\n",
    "\n",
    "pyro.clear_param_store()\n",
    "print(\"=== Sampling ===\")\n",
    "model()\n",
    "print(\"=== Enumerated Inference ===\")\n",
    "elbo = TraceEnum_ELBO()\n",
    "elbo.loss(model, guide)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CASE I: scalar indexing ===\n",
      "torch.Size([2, 5])\n",
      "=== CASE II: vector indexing ===\n",
      "torch.Size([3, 2, 5])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "=== CASE III: vector indexing with broadcasting ===\n",
      "torch.Size([3, 2, 5])\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    vanilla indexing\n",
    "\"\"\"\n",
    "\n",
    "x = torch.rand(2, 4, 5, 6)\n",
    "\n",
    "\n",
    "print(\"=== CASE I: scalar indexing ===\")\n",
    "# take the slice of x where \n",
    "#   2nd-dim is 0 and 4th-dim is 0\n",
    "# return a slice whose shape is\n",
    "#   [2, 5]\n",
    "y = x[..., 0, :, 0]\n",
    "print(y.shape)\n",
    "\n",
    "print(\"=== CASE II: vector indexing ===\")\n",
    "# take the slice of x where \n",
    "#   2nd-dim is 0 and 4th-dim is 3\n",
    "#   2nd-dim is 1 and 4th-dim is 1\n",
    "#   2nd-dim is 1 and 4th-dim is 2\n",
    "# return 3 slices whose shape is\n",
    "#   [3, 2, 5]\n",
    "y = x[..., torch.tensor([0, 1, 1]), :, torch.tensor([3, 1, 2])]\n",
    "print(y.shape)\n",
    "print(y[0] - x[:, 0, :, 3])\n",
    "\n",
    "print(\"=== CASE III: vector indexing with broadcasting ===\")\n",
    "# take the slice of x where \n",
    "#   2nd-dim is 0 and 4th-dim is 3\n",
    "#   2nd-dim is 1 and 4th-dim is 3\n",
    "#   2nd-dim is 1 and 4th-dim is 3\n",
    "# return 3 slices whose shape is\n",
    "#   [3, 2, 5]\n",
    "y = x[..., torch.tensor([0, 1, 1]), :, torch.tensor([3])]\n",
    "print(y.shape)\n",
    "print(y[1] - x[:, 1, :, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CASE I: trivial case ===\n",
      "torch.Size([2, 5])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "=== CASE II: broadcasting original tensor ===\n",
      "torch.Size([2, 2, 5])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "=== CASE III: broadcasting index tensor\n",
      "torch.Size([7, 2, 5])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "=== CASE III: broadcasting both\n",
      "torch.Size([2, 2, 5])\n",
      "tensor([0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    v-index (or batch indexing)\n",
    "\n",
    "    KEY: ellipse(...) denote batch dimension!\n",
    "\"\"\"\n",
    "\n",
    "x = torch.rand(2, 4, 5, 6)\n",
    "\n",
    "print(\"=== CASE I: trivial case ===\")\n",
    "# batch_index_select\n",
    "#   x[0]'s shape is [4, 5, 6], index select by [0] and [3]\n",
    "#   x[1]'s shape is [4, 5, 6], index select by [2] and [2]\n",
    "y = Vindex(x)[..., torch.tensor([0, 2]), :, torch.tensor([3, 2])]\n",
    "print(y.shape)\n",
    "print(y[0] - x[0, 0, :, 3])\n",
    "print(y[1] - x[1, 2, :, 2])\n",
    "\n",
    "print(\"=== CASE II: broadcasting original tensor ===\")\n",
    "# shape:\n",
    "#   x  is [2 | 4 5 6]\n",
    "#   i1 is [2 2]\n",
    "#   i2 is [2 2]\n",
    "# broadcast:\n",
    "#   x's shape [_ 2 | 4 5 6 ]-> [2 2 | 4 5 6]\n",
    "# finally:\n",
    "#   y[i, j] = x[i, j, i1[i][j], :, i2[i][j]]\n",
    "y = Vindex(x)[..., torch.tensor([[0, 2], [0, 3]]), :, torch.tensor([[3, 2], [3, 2]])]\n",
    "print(y.shape)\n",
    "print(y[0][0] - x[0, 0, :, 3])\n",
    "print(y[0][1] - x[1, 2, :, 2])\n",
    "print(y[1][0] - x[0, 0, :, 3])\n",
    "print(y[1][1] - x[1, 3, :, 2])\n",
    "\n",
    "\n",
    "print(\"=== CASE III: broadcasting index tensor\")\n",
    "# shape:\n",
    "#   x  is [7 2 | 4 5 6]\n",
    "#   i1 is [2]\n",
    "#   i2 is [2]\n",
    "# broadcast:\n",
    "#   i's shape [_ 2]-> [7 2]\n",
    "# finally:\n",
    "x = torch.rand(7, 2, 4, 5, 6)\n",
    "y = Vindex(x)[..., torch.tensor([0, 2]), :, torch.tensor([3, 2])]\n",
    "print(y.shape)\n",
    "print(y[5][0] - x[5, 0, 0, :, 3])\n",
    "print(y[2][1] - x[2, 1, 2, :, 2])\n",
    "\n",
    "\n",
    "print(\"=== CASE III: broadcasting both\")\n",
    "# shape:\n",
    "#   x  is [2 | 4 5 6]\n",
    "#   i1 is [2 1]\n",
    "#   i2 is [2 1]\n",
    "# broadcast:\n",
    "#   x's shape [2 | 4 5 6] -> [2 2 | 4 5 6]\n",
    "#   i's shape [2 1] -> [2 2]\n",
    "#   NOTE: [2] + [2, 1]? == [2, 2], != [2, 1]\n",
    "# finally:\n",
    "#   - x[<0>, i, 0, :, 3] == y[0, i]\n",
    "x = torch.rand(2, 4, 5, 6)\n",
    "y = Vindex(x)[..., torch.tensor([[0], [2]]), :, torch.tensor([[3], [2]])]\n",
    "print(y.shape)\n",
    "i = 1\n",
    "print(y[0, i] - x[i, 0, :, 3])\n",
    "print(y[1, i] - x[i, 2, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO before: 186.62033081054688\n",
      "ELBO after: 27.53680419921875\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'AutoDelta.weights'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6428</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3572</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'AutoDelta.loc'</span>: Parameter containing:\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.6208</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.1366</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">requires_grad</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'AutoDelta.weights'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.6428\u001b[0m, \u001b[1;36m0.3572\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'AutoDelta.loc'\u001b[0m: Parameter containing:\n",
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m12.6208\u001b[0m,  \u001b[1;36m1.1366\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mrequires_grad\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sampling ===\n",
      "=== MAP ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    We marginalize all possible assignments in the model.\n",
    "    \n",
    "\"\"\"\n",
    "@config_enumerate\n",
    "def model(data, num_components=2):\n",
    "    weights = pyro.sample(\"weights\", dist.Dirichlet(0.5 * torch.ones(num_components)))\n",
    "    with pyro.plate(\"components\", num_components):\n",
    "        loc = pyro.sample(\"loc\", dist.Normal(5, 3))\n",
    "        scale = torch.tensor([1.0, 1.0])\n",
    "    with pyro.plate(\"data\", len(data)):\n",
    "        # for each datum (more precisely, `for i in range(len(data))` \n",
    "        #   since the datum is not observed yet)\n",
    "        assignment = pyro.sample(\"assignment\", dist.Categorical(weights))\n",
    "        obs_dist = dist.Normal(loc[assignment], scale[assignment])\n",
    "        obs = pyro.sample(\"obs\", obs_dist, obs=data)\n",
    "\n",
    "data = torch.tensor([0, 1, 2, 11, 12, 13, 14, 15])\n",
    "pyro.clear_param_store()\n",
    "\n",
    "guide = AutoDelta(poutine.block(model, hide=['assignment']))\n",
    "elbo = TraceEnum_ELBO(num_particles=1)\n",
    "opt = pyro.optim.AdamW({\"lr\": 0.1})\n",
    "svi = SVI(model, guide, opt, elbo)\n",
    "\n",
    "print(f\"ELBO before: {elbo.loss(model, guide, data)}\")\n",
    "\n",
    "# train\n",
    "losses = []\n",
    "for i in range(500):\n",
    "    loss = svi.step(data)\n",
    "    losses.append(loss)\n",
    "# plt.plot(losses)\n",
    "# plt.show()\n",
    "\n",
    "print(f\"ELBO after: {elbo.loss(model, guide, data)}\")\n",
    "\n",
    "rich.print(dict(pyro.get_param_store()))\n",
    "\n",
    "# render_model_plus(model, (data, ))\n",
    "# render_model_plus(guide, (data, ))\n",
    "\n",
    "print(\"=== Sampling ===\")\n",
    "model(data)\n",
    "\n",
    "print(\"=== MAP ===\")\n",
    "map_model = infer_discrete(model, first_available_dim=-2, temperature=0)\n",
    "rich.print(dict(poutine.trace(map_model).get_trace(data).nodes)['assignment']['value'])\n",
    "# pyro.render_model(map, (data, ), render_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    In the guide trained before, the assignment is not determined, since it will be marginalized in the model.\n",
    "\n",
    "    Two ways to train a guide to approximate the posterior:\n",
    "        - Fix the trained cluster centers, only train the assignment for each data.\n",
    "        - Use a guide with all possible assignments!\n",
    "\n",
    "\"\"\"\n",
    "@config_enumerate\n",
    "def full_guide(data):\n",
    "    # Global variables\n",
    "    # We can keep our learned values of global parameters:\n",
    "    # with poutine.block(hide_types=[\"param\"]):  \n",
    "    #     guide(data)\n",
    "    guide(data)\n",
    "\n",
    "    # Local variables\n",
    "    with pyro.plate('data', len(data)):\n",
    "        assignment_probs = pyro.param('assignment_probs', torch.ones(len(data), 2) / 2,\n",
    "                                      constraint=constraints.unit_interval)\n",
    "        pyro.sample('assignment', dist.Categorical(assignment_probs))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "optim = pyro.optim.AdamW({'lr': 0.2, 'betas': [0.8, 0.99]})\n",
    "elbo = TraceEnum_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model, full_guide, optim, loss=elbo)\n",
    "\n",
    "losses = []\n",
    "for i in range(500):\n",
    "    loss = svi.step(data)\n",
    "    losses.append(loss)\n",
    "plt.plot(losses)\n",
    "\n",
    "rich.print(dict(pyro.get_param_store()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Dummy Step 1\n",
      "c torch.Size([256]) torch.Size([256])\n",
      "x torch.Size([256]) torch.Size([256])\n",
      "c torch.Size([256]) torch.Size([256])\n",
      "x torch.Size([256]) torch.Size([256])\n",
      "c torch.Size([2, 1]) torch.Size([2, 1, 1])\n",
      "x torch.Size([256]) torch.Size([256])\n",
      "Dummy Step 2\n",
      "c torch.Size([2, 1]) torch.Size([2, 1, 1])\n",
      "x torch.Size([256]) torch.Size([256])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1388</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8612</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'trans'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8908</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1092</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2324</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7676</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'emiss'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2189</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1434</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6377</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7290</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2238</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0472</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'state'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.1388\u001b[0m, \u001b[1;36m0.8612\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'trans'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.8908\u001b[0m, \u001b[1;36m0.1092\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.2324\u001b[0m, \u001b[1;36m0.7676\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'emiss'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.2189\u001b[0m, \u001b[1;36m0.1434\u001b[0m, \u001b[1;36m0.6377\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.7290\u001b[0m, \u001b[1;36m0.2238\u001b[0m, \u001b[1;36m0.0472\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'state'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span><span style=\"font-weight: bold\">])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'trans'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7000</span><span style=\"font-weight: bold\">]])</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'emiss'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span><span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2000</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7000</span><span style=\"font-weight: bold\">]])</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "    \u001b[32m'state'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.9000\u001b[0m, \u001b[1;36m0.1000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'trans'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.8000\u001b[0m, \u001b[1;36m0.2000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.3000\u001b[0m, \u001b[1;36m0.7000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
       "    \u001b[32m'emiss'\u001b[0m: \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.7000\u001b[0m, \u001b[1;36m0.2000\u001b[0m, \u001b[1;36m0.1000\u001b[0m\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0m\u001b[1;36m0.1000\u001b[0m, \u001b[1;36m0.2000\u001b[0m, \u001b[1;36m0.7000\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Design a HMM1 to generate the data and train a HMM2 to fit the data.\n",
    "\n",
    "    - Everything is discrete, use `enumerate` for marginalization!\n",
    "    - The HMM2 will fit the data, but it does not mean it has the same parameter\n",
    "        as HMM1. The generated distributions will be close.\n",
    "\"\"\"\n",
    "COVID_PARAM = dict(\n",
    "    state = torch.tensor(\n",
    "        [0.9, 0.1]    # negative, positive\n",
    "    ),\n",
    "    trans = torch.tensor([\n",
    "        [0.8, 0.2],\n",
    "        [0.3, 0.7]    \n",
    "    ]),\n",
    "    emiss = torch.tensor([\n",
    "        [0.7, 0.2, 0.1],   # 家, 隔离点, 方仓\n",
    "        [0.1, 0.2, 0.7]\n",
    "    ])\n",
    ")\n",
    "\n",
    "def covid(x):\n",
    "    state, trans, emiss = COVID_PARAM['state'], COVID_PARAM['trans'], COVID_PARAM['emiss']\n",
    "    with pyro.plate(\"data\", len(x)):\n",
    "        c1 = pyro.sample(\"c1\", dist.Categorical(state))\n",
    "        c2 = pyro.sample(\"c2\", dist.Categorical(trans[c1]))\n",
    "        x1 = pyro.sample(\"x1\", dist.Categorical(emiss[c1]))\n",
    "        x2 = pyro.sample(\"x2\", dist.Categorical(emiss[c2]))\n",
    "        return torch.stack([x1, x2], dim=-1)\n",
    "\n",
    "@config_enumerate\n",
    "def model(data, debug):\n",
    "    state = pyro.param(\"state\", torch.rand(2), constraints.simplex)\n",
    "    trans = pyro.param(\"trans\", torch.rand(2, 2), constraints.simplex)\n",
    "    emiss = pyro.param(\"emiss\", torch.rand(2, 3), constraints.simplex)\n",
    "    # state = pyro.param('state', COVID_PARAM['state'].clone(), constraints.simplex)\n",
    "    # trans = pyro.param('trans', COVID_PARAM['trans'].clone(), constraints.simplex)\n",
    "    # emiss = pyro.param('emiss', COVID_PARAM['emiss'].clone(), constraints.simplex)\n",
    "    with pyro.plate(\"data\", size=len(data)):\n",
    "        c1 = pyro.sample(\"c1\", dist.Categorical(state))\n",
    "        c2 = pyro.sample(\"c2\", dist.Categorical(trans[c1]))\n",
    "        x1 = pyro.sample(\"x1\", dist.Categorical(emiss[c1]))\n",
    "        x2 = pyro.sample(\"x2\", dist.Categorical(emiss[c2]))\n",
    "        if debug:\n",
    "            print(\"c\", c1.shape, c2.shape)\n",
    "            print(\"x\", x1.shape, x2.shape)\n",
    "            return torch.stack([x1, x2], dim=-1)\n",
    "\n",
    "data = covid(list(range(256)))\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "cond_model = poutine.condition(model, data={\"x1\": data[:, 0], \"x2\": data[:, 1]})\n",
    "# render_model_plus(cond_model, (data, False))\n",
    "guide = AutoDelta(poutine.block(model, hide=['c1', 'c2', 'x1', 'x2']))\n",
    "# render_model_plus(guide, (data, False))\n",
    "\n",
    "elbo = TraceEnum_ELBO()\n",
    "opt = pyro.optim.AdamW({\"lr\": 0.01})\n",
    "svi = SVI(cond_model, guide, opt, elbo)\n",
    "\n",
    "# dummy step\n",
    "print(\"Dummy Step 1\")\n",
    "svi.step(data, True)\n",
    "print(\"Dummy Step 2\")\n",
    "svi.step(data, True)\n",
    "\n",
    "# training\n",
    "losses = []\n",
    "for i in range(600):\n",
    "    # print(f\"Step {i}\")\n",
    "    loss = svi.step(data, False)\n",
    "    losses.append(loss / len(data))\n",
    "plt.plot(losses)\n",
    "rich.print(dict(pyro.get_param_store()))\n",
    "rich.print(COVID_PARAM)\n",
    "\n",
    "out = list(map(tuple, model(data, True).tolist()))\n",
    "real = list(map(tuple, data.tolist()))\n",
    "\n",
    "print(\"=== Generated Distribution ===\")\n",
    "from collections import Counter\n",
    "print(Counter(out))\n",
    "print(Counter(real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15599cad0da4c5da1b184cfd1e470e7358b141a55537aea656512ec5dac1993"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 ('pyro')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
